# -*- coding: utf-8 -*-
"""Scraping StatsGuru

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VFz8hoUnydjmhHGhha-yIk3uKfTu-xK7
"""

import pandas as pd
from urllib.request import urlopen
from bs4 import BeautifulSoup

url = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=2;orderby=batted_score;spanmax1=31+Dec+2019;spanmin1=01+Jan+2001;spanval1=span;template=results;type=batting;view=innings"
text = urlopen(url)
soup = BeautifulSoup(text , "lxml")

all_tables = soup.findAll('table',attrs = {'class':'engineTable'})

len(all_tables)

int_table = all_tables[0]
for table in all_tables:
  caption = table.findAll('caption')
  if(len(caption)>0):
    int_table = table

tr_list = int_table.findAll('tr',attrs = {'class':'data1'})

len(tr_list)

first_row = tr_list[0]
first_row

first_row_data = []
td_list = first_row.findAll('td')

for td in td_list:
  td_str = str(td)
  cleantext = BeautifulSoup(td_str,"lxml").get_text()
  first_row_data.append(cleantext)

first_row_data

master_data = []
for tr in tr_list:
  row_data = []
  td_list = tr.findAll('td')
  for td in td_list:
    td_str = str(td)
    cleantext = BeautifulSoup(td_str,"lxml").get_text()
    row_data.append(cleantext)
  #print(row_data)
  master_data.append(row_data)

df = pd.DataFrame(master_data)

master_data = []
for k in range(1,1131):
    url = "https://stats.espncricinfo.com/ci/engine/stats/index.html?class=2;page=" + str(k) + ";spanmax1=31+dec+2019;spanmin1=01+jan+2001;spanval1=span;template=results;type=batting;view=innings"
    text = urlopen(url)
    soup = BeautifulSoup(text, "lxml")
    all_tables = soup.findAll('table', attrs={'class':'engineTable'})
    int_table = all_tables[0]
    for table in all_tables:
        caption = table.findAll('caption')
        if(len(caption)>0):
            int_table = table
    tr_list = int_table.findAll('tr', attrs={'class':'data1'})
    for tr in tr_list:
        row_data = []
        td_list = tr.findAll('td')
        for td in td_list:
            td_str = str(td)
            cleantext = BeautifulSoup(td_str, "lxml").get_text()
            row_data.append(cleantext)
        master_data.append(row_data)

df = pd.DataFrame(master_data)

df.to_csv('./data.csv', index=False)